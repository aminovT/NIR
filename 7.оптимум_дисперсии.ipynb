{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score,classification_report,f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as utils\n",
    "from torch.optim import Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.Subset(datasets.MNIST('MNIST_data/', train=True, download=False,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           \n",
    "                       ])) , list(range(0 , 60000 , 100))),\n",
    "        batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('MNIST_data/', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           \n",
    "                       ])),\n",
    "        batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15008"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_pr_loss(a , variance):\n",
    "    k = len(a[0])\n",
    "    l = torch.sum(a**2)/ variance**2 /2/k\n",
    "    return l  #k/2*math.log(2*math.pi) + 0.5*k*math.log(variance) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eva(test_loader , model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.view(data.size(0), -1)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return (test_loss ,correct / len(test_loader.dataset) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential()\n",
    "    model.add_module('l1', nn.Linear(784, 400))\n",
    "    model.add_module('r1', nn.Sigmoid())\n",
    "    model.add_module('l2', nn.Linear(400, 400))\n",
    "    model.add_module('r2', nn.Sigmoid())\n",
    "    model.add_module('l3', nn.Linear(400, 400))\n",
    "    model.add_module('r3', nn.Sigmoid())\n",
    "    model.add_module('l4', nn.Linear(400, 400))\n",
    "    model.add_module('r4', nn.Sigmoid())\n",
    "    model.add_module('l5', nn.Linear(400, 400))\n",
    "    model.add_module('r5', nn.Sigmoid())\n",
    "    model.add_module('lf', nn.Linear(400, 10))\n",
    "\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200 = 1\n",
    "m_784 = 1\n",
    "NUM_EPOCH = 200\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 3.59381366e+00, 1.29154967e+01, 4.64158883e+01,\n",
       "       1.66810054e+02, 5.99484250e+02, 2.15443469e+03, 7.74263683e+03,\n",
       "       2.78255940e+04, 1.00000000e+05])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(0 , 5 , 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var = 1.0 Train Epoch: 100 [216/600 (90%)]\tLoss: 2.294958 \n",
      "\n",
      "Test set: Average loss: 0.0362, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "var = 3.5938136638046276 Train Epoch: 100 [216/600 (90%)]\tLoss: 2.292208 \n",
      "\n",
      "Test set: Average loss: 0.0362, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "var = 12.91549665014884 Train Epoch: 100 [216/600 (90%)]\tLoss: 0.187644 \n",
      "\n",
      "Test set: Average loss: 0.0290, Accuracy: 7195/10000 (72%)\n",
      "\n",
      "var = 46.4158883361278 Train Epoch: 100 [216/600 (90%)]\tLoss: 0.303501 \n",
      "\n",
      "Test set: Average loss: 0.0242, Accuracy: 7593/10000 (76%)\n",
      "\n",
      "var = 166.81005372000593 Train Epoch: 100 [216/600 (90%)]\tLoss: 0.021097 \n",
      "\n",
      "Test set: Average loss: 0.0240, Accuracy: 7663/10000 (77%)\n",
      "\n",
      "var = 599.4842503189409 Train Epoch: 100 [216/600 (90%)]\tLoss: 0.242127 \n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 7653/10000 (77%)\n",
      "\n",
      "var = 2154.4346900318847 Train Epoch: 100 [216/600 (90%)]\tLoss: 0.145727 \n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 7492/10000 (75%)\n",
      "\n",
      "var = 7742.636826811277 Train Epoch: 100 [216/600 (90%)]\tLoss: 0.167351 \n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 7358/10000 (74%)\n",
      "\n",
      "var = 27825.59402207126 Train Epoch: 100 [216/600 (90%)]\tLoss: 0.298138 \n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 7509/10000 (75%)\n",
      "\n",
      "var = 100000.0 Train Epoch: 100 [216/600 (90%)]\tLoss: 0.029090 \n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 7525/10000 (75%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_acc = []\n",
    "history = []\n",
    "for m_200 in np.logspace(0 , 5 , 10):\n",
    "    NUM_EPOCH = 200\n",
    "    model = get_model()\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "    model.train()\n",
    "    step = 0 \n",
    "    loss_history = []\n",
    "    loss_p = []\n",
    "    for epoch in range(1, NUM_EPOCH):\n",
    "        for batch_idx, (data, target) in enumerate(trainloader):\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.view(data.size(0), -1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss_0 = criterion(output, target)\n",
    "            loss_1 = call_pr_loss(model.l1.weight , m_200)\n",
    "            loss_2 = call_pr_loss(model.l2.weight , m_200)\n",
    "            loss_3 = call_pr_loss(model.l3.weight , m_200)\n",
    "            loss_4 = call_pr_loss(model.l4.weight , m_200)\n",
    "            loss_5 = call_pr_loss(model.l5.weight , m_200)\n",
    "            #loss_f = call_pr_loss(model.lf.weight , m_200)\n",
    "\n",
    "\n",
    "            loss = loss_0 + loss_1+ loss_2+ loss_3 +  loss_4 + loss_5 #+ loss_f\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "            loss_history.append(loss.item())\n",
    "            loss_p.append(loss_0.item())\n",
    "            if step % 1000  == 0:\n",
    "                print('var = {} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} '.format(\n",
    "                    m_200,\n",
    "                    epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                    100. * batch_idx / len(trainloader), loss.item()))\n",
    "\n",
    "    history_acc.append(eva(test_loader , model))\n",
    "    history.append((loss_history , loss_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = []\n",
    "for i in history_acc:\n",
    "    his.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.logspace(0 , 5 , 10) , his)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.Subset(datasets.MNIST('MNIST_data/', train=True, download=False,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           \n",
    "                       ])) , list(range(0 , 60000 ))),\n",
    "        batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('MNIST_data/', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           \n",
    "                       ])),\n",
    "        batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var = 1.0 Train Epoch: 2 [3904/60000 (7%)]\tLoss: 2.334471 \n",
      "var = 1.0 Train Epoch: 3 [7872/60000 (13%)]\tLoss: 2.312900 \n",
      "var = 1.0 Train Epoch: 4 [11840/60000 (20%)]\tLoss: 2.313036 \n",
      "\n",
      "Test set: Average loss: 0.0362, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "var = 3.5938136638046276 Train Epoch: 2 [3904/60000 (7%)]\tLoss: 2.308225 \n",
      "var = 3.5938136638046276 Train Epoch: 3 [7872/60000 (13%)]\tLoss: 2.312685 \n",
      "var = 3.5938136638046276 Train Epoch: 4 [11840/60000 (20%)]\tLoss: 2.307365 \n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "var = 12.91549665014884 Train Epoch: 2 [3904/60000 (7%)]\tLoss: 0.402448 \n",
      "var = 12.91549665014884 Train Epoch: 3 [7872/60000 (13%)]\tLoss: 0.236617 \n",
      "var = 12.91549665014884 Train Epoch: 4 [11840/60000 (20%)]\tLoss: 0.067637 \n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 9569/10000 (96%)\n",
      "\n",
      "var = 46.4158883361278 Train Epoch: 2 [3904/60000 (7%)]\tLoss: 0.445093 \n",
      "var = 46.4158883361278 Train Epoch: 3 [7872/60000 (13%)]\tLoss: 0.123638 \n",
      "var = 46.4158883361278 Train Epoch: 4 [11840/60000 (20%)]\tLoss: 0.123278 \n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 9645/10000 (96%)\n",
      "\n",
      "var = 166.81005372000593 Train Epoch: 2 [3904/60000 (7%)]\tLoss: 0.399528 \n",
      "var = 166.81005372000593 Train Epoch: 3 [7872/60000 (13%)]\tLoss: 0.280307 \n",
      "var = 166.81005372000593 Train Epoch: 4 [11840/60000 (20%)]\tLoss: 0.043223 \n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 9617/10000 (96%)\n",
      "\n",
      "var = 599.4842503189409 Train Epoch: 2 [3904/60000 (7%)]\tLoss: 0.254924 \n",
      "var = 599.4842503189409 Train Epoch: 3 [7872/60000 (13%)]\tLoss: 0.136364 \n",
      "var = 599.4842503189409 Train Epoch: 4 [11840/60000 (20%)]\tLoss: 0.025149 \n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 9638/10000 (96%)\n",
      "\n",
      "var = 2154.4346900318847 Train Epoch: 2 [3904/60000 (7%)]\tLoss: 0.246700 \n",
      "var = 2154.4346900318847 Train Epoch: 3 [7872/60000 (13%)]\tLoss: 0.175683 \n",
      "var = 2154.4346900318847 Train Epoch: 4 [11840/60000 (20%)]\tLoss: 0.025436 \n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 9609/10000 (96%)\n",
      "\n",
      "var = 7742.636826811277 Train Epoch: 2 [3904/60000 (7%)]\tLoss: 0.278076 \n",
      "var = 7742.636826811277 Train Epoch: 3 [7872/60000 (13%)]\tLoss: 0.254946 \n",
      "var = 7742.636826811277 Train Epoch: 4 [11840/60000 (20%)]\tLoss: 0.142772 \n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 9636/10000 (96%)\n",
      "\n",
      "var = 27825.59402207126 Train Epoch: 2 [3904/60000 (7%)]\tLoss: 0.288693 \n",
      "var = 27825.59402207126 Train Epoch: 3 [7872/60000 (13%)]\tLoss: 0.047692 \n",
      "var = 27825.59402207126 Train Epoch: 4 [11840/60000 (20%)]\tLoss: 0.094542 \n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 9657/10000 (97%)\n",
      "\n",
      "var = 100000.0 Train Epoch: 2 [3904/60000 (7%)]\tLoss: 0.123227 \n",
      "var = 100000.0 Train Epoch: 3 [7872/60000 (13%)]\tLoss: 0.156679 \n",
      "var = 100000.0 Train Epoch: 4 [11840/60000 (20%)]\tLoss: 0.037367 \n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 9635/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_acc = []\n",
    "history = []\n",
    "for m_200 in np.logspace(0 , 5 , 10):\n",
    "    NUM_EPOCH = 5\n",
    "    model = get_model()\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "    model.train()\n",
    "    step = 0 \n",
    "    loss_history = []\n",
    "    loss_p = []\n",
    "    for epoch in range(1, NUM_EPOCH):\n",
    "        for batch_idx, (data, target) in enumerate(trainloader):\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.view(data.size(0), -1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss_0 = criterion(output, target)\n",
    "            loss_1 = call_pr_loss(model.l1.weight , m_200)\n",
    "            loss_2 = call_pr_loss(model.l2.weight , m_200)\n",
    "            loss_3 = call_pr_loss(model.l3.weight , m_200)\n",
    "            loss_4 = call_pr_loss(model.l4.weight , m_200)\n",
    "            loss_5 = call_pr_loss(model.l5.weight , m_200)\n",
    "            #loss_f = call_pr_loss(model.lf.weight , m_200)\n",
    "\n",
    "\n",
    "            loss = loss_0 + loss_1+ loss_2+ loss_3 +  loss_4 + loss_5 #+ loss_f\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "            loss_history.append(loss.item())\n",
    "            loss_p.append(loss_0.item())\n",
    "            if step % 1000  == 0:\n",
    "                print('var = {} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} '.format(\n",
    "                    m_200,\n",
    "                    epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                    100. * batch_idx / len(trainloader), loss.item()))\n",
    "\n",
    "    history_acc.append(eva(test_loader , model))\n",
    "    history.append((loss_history , loss_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = []\n",
    "for i in history_acc:\n",
    "    his.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.logspace(0 , 5 , 10) , his)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
